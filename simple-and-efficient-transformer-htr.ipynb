{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48fb9b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:11:28.127666Z",
     "iopub.status.busy": "2023-06-16T02:11:28.127096Z",
     "iopub.status.idle": "2023-06-16T02:11:50.204507Z",
     "shell.execute_reply": "2023-06-16T02:11:50.203567Z"
    },
    "papermill": {
     "duration": 22.090236,
     "end_time": "2023-06-16T02:11:50.206721",
     "exception": false,
     "start_time": "2023-06-16T02:11:28.116485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.16)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.2.3)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.0.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.27.1)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.5.12)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.2)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.9)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.27)\r\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.11.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.2.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.8.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhants2002\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230616_021143-2723dr58</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/minhants2002/160623/runs/2723dr58\" target=\"_blank\">silver-frog-1</a></strong> to <a href=\"https://wandb.ai/minhants2002/160623\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install wandb \n",
    "\n",
    "import wandb \n",
    "wandb.login(key = '')\n",
    "\n",
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\":  2e-6,\n",
    "    \"architecture\": \"CNN + Transformer\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c651507e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-16T02:11:50.232819Z",
     "iopub.status.busy": "2023-06-16T02:11:50.231892Z",
     "iopub.status.idle": "2023-06-16T02:12:02.515142Z",
     "shell.execute_reply": "2023-06-16T02:12:02.514060Z"
    },
    "papermill": {
     "duration": 12.300029,
     "end_time": "2023-06-16T02:12:02.518280",
     "exception": false,
     "start_time": "2023-06-16T02:11:50.218251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Augmentor\r\n",
      "  Downloading Augmentor-0.2.12-py2.py3-none-any.whl (38 kB)\r\n",
      "Collecting editdistance\r\n",
      "  Downloading editdistance-0.6.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.9.0 in /opt/conda/lib/python3.7/site-packages (from Augmentor) (4.64.0)\r\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /opt/conda/lib/python3.7/site-packages (from Augmentor) (9.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from Augmentor) (1.21.6)\r\n",
      "Installing collected packages: editdistance, Augmentor\r\n",
      "Successfully installed Augmentor-0.2.12 editdistance-0.6.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Augmentor editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533f9819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:02.545072Z",
     "iopub.status.busy": "2023-06-16T02:12:02.544647Z",
     "iopub.status.idle": "2023-06-16T02:12:04.701801Z",
     "shell.execute_reply": "2023-06-16T02:12:04.700795Z"
    },
    "papermill": {
     "duration": 2.170946,
     "end_time": "2023-06-16T02:12:04.704681",
     "exception": false,
     "start_time": "2023-06-16T02:12:02.533735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "import Augmentor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d, MaxPool2d, BatchNorm2d, LeakyReLU\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import editdistance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66493403",
   "metadata": {
    "papermill": {
     "duration": 0.008935,
     "end_time": "2023-06-16T02:12:04.723593",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.714658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df37ae1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:04.744272Z",
     "iopub.status.busy": "2023-06-16T02:12:04.743558Z",
     "iopub.status.idle": "2023-06-16T02:12:04.749793Z",
     "shell.execute_reply": "2023-06-16T02:12:04.749064Z"
    },
    "papermill": {
     "duration": 0.019255,
     "end_time": "2023-06-16T02:12:04.751771",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.732516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = './' # work directory\n",
    "PATH_TEST_DIR = '/kaggle/input/data-gray/images/'\n",
    "PATH_TEST_LABELS =  '/kaggle/input/data-gray/val.csv'\n",
    "PATH_TRAIN_DIR =  '/kaggle/input/data-gray/images/'\n",
    "PATH_TRAIN_LABELS =  '/kaggle/input/data-gray/train.csv'\n",
    "\n",
    "PREDICT_PATH = \"/kaggle/input/test-data/test/\"\n",
    "CHECKPOINT_PATH = DIR\n",
    "WEIGHTS_PATH =  None\n",
    "PATH_TEST_RESULTS = DIR+'/test_result.tsv'\n",
    "TRAIN_LOG = DIR+'train_log.tsv' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b42b761c",
   "metadata": {
    "papermill": {
     "duration": 0.010224,
     "end_time": "2023-06-16T02:12:04.771202",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.760978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd3258b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:04.797499Z",
     "iopub.status.busy": "2023-06-16T02:12:04.797134Z",
     "iopub.status.idle": "2023-06-16T02:12:04.805847Z",
     "shell.execute_reply": "2023-06-16T02:12:04.804841Z"
    },
    "papermill": {
     "duration": 0.022834,
     "end_time": "2023-06-16T02:12:04.808940",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.786106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### MODEL ### \n",
    "MODEL = 'model2'\n",
    "HIDDEN = 512\n",
    "ENC_LAYERS = 2\n",
    "DEC_LAYERS = 2\n",
    "N_HEADS = 4\n",
    "LENGTH = 42\n",
    "ALPHABET = ['PAD', 'SOS', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'EOS']\n",
    "            \n",
    "### TRAINING ###\n",
    "BATCH_SIZE = 64\n",
    "DROPOUT = 0.2\n",
    "N_EPOCHS = 10\n",
    "CHECKPOINT_FREQ = 5 # save checkpoint every 10 epochs\n",
    "DEVICE = 'cuda:0' # or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "RANDOM_SEED = 42\n",
    "SCHUDULER_ON = True # \"ReduceLROnPlateau\"\n",
    "PATIENCE = 5 # for ReduceLROnPlateau\n",
    "OPTIMIZER_NAME = 'Adam' # or \"SGD\"\n",
    "\n",
    "LR = 0.00001\n",
    "\n",
    "### TESTING ###\n",
    "CASE = False # is case taken into account or not while evaluating\n",
    "PUNCT = False # are punctuation marks taken into account\n",
    "\n",
    "### INPUT IMAGE PARAMETERS ###\n",
    "WIDTH = 256\n",
    "HEIGHT = 64\n",
    "CHANNELS = 1 # 3 channels if model1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1321544f",
   "metadata": {
    "papermill": {
     "duration": 0.008803,
     "end_time": "2023-06-16T02:12:04.828938",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.820135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69307901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:04.848739Z",
     "iopub.status.busy": "2023-06-16T02:12:04.848429Z",
     "iopub.status.idle": "2023-06-16T02:12:04.909118Z",
     "shell.execute_reply": "2023-06-16T02:12:04.908299Z"
    },
    "papermill": {
     "duration": 0.073387,
     "end_time": "2023-06-16T02:12:04.911355",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.837968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.scale = torch.nn.Parameter(torch.ones(1))\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(\n",
    "            0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.scale * self.pe[:x.size(0), :]\n",
    "        return self.dropout(x) \n",
    "\n",
    "    \n",
    "# convert images and labels into defined data structures\n",
    "def process_data(image_dir, labels_dir, ignore=[]):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    image_dir : str\n",
    "      path to directory with images\n",
    "    labels_dir : str\n",
    "      path to tsv file with labels\n",
    "    returns\n",
    "    ---\n",
    "    img2label : dict\n",
    "      keys are names of images and values are correspondent labels\n",
    "    chars : list\n",
    "      all unique chars used in data\n",
    "    all_labels : list\n",
    "    \"\"\"\n",
    "\n",
    "    chars = []\n",
    "    img2label = dict()\n",
    "\n",
    "    raw = open(labels_dir, 'r', encoding='utf-8').read()\n",
    "    temp = raw.split('\\n')\n",
    "    for t in temp:\n",
    "        try:\n",
    "            x = t.split(',')\n",
    "            flag = False\n",
    "            for item in ignore:\n",
    "                if item in x[1]:\n",
    "                    flag = True\n",
    "            if flag == False:\n",
    "                img2label[image_dir + x[0]] = x[1]\n",
    "                for char in x[1]:\n",
    "                    if char not in chars:\n",
    "                        chars.append(char)\n",
    "        except:\n",
    "            print('ValueError:', x)\n",
    "            pass\n",
    "\n",
    "    all_labels = sorted(list(set(list(img2label.values()))))\n",
    "    chars.sort()\n",
    "    chars = ['PAD', 'SOS'] + chars + ['EOS']\n",
    "\n",
    "    return img2label, chars, all_labels\n",
    "\n",
    "\n",
    "# TRANSLATE INDICIES TO TEXT\n",
    "def indicies_to_text(indexes, idx2char):\n",
    "    text = \"\".join([idx2char[i] for i in indexes])\n",
    "    text = text.replace('EOS', '').replace('PAD', '').replace('SOS', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "# COMPUTE CHARACTER ERROR RATE\n",
    "def char_error_rate(p_seq1, p_seq2):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    p_seq1 : str\n",
    "    p_seq2 : str\n",
    "    returns\n",
    "    ---\n",
    "    cer : float\n",
    "    \"\"\"\n",
    "    p_vocab = set(p_seq1 + p_seq2)\n",
    "    p2c = dict(zip(p_vocab, range(len(p_vocab))))\n",
    "    c_seq1 = [chr(p2c[p]) for p in p_seq1]\n",
    "    c_seq2 = [chr(p2c[p]) for p in p_seq2]\n",
    "    return editdistance.eval(''.join(c_seq1),\n",
    "                             ''.join(c_seq2)) / max(len(c_seq1), len(c_seq2))\n",
    "\n",
    "\n",
    "# RESIZE AND NORMALIZE IMAGE\n",
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    ---\n",
    "    img : np.array\n",
    "    returns\n",
    "    ---\n",
    "    img : np.array\n",
    "    \"\"\"\n",
    "    w, h, _ = img.shape\n",
    "    new_w = HEIGHT\n",
    "    new_h = int(h * (new_w / w))\n",
    "    img = cv2.resize(img, (new_h, new_w))\n",
    "    w, h, _ = img.shape\n",
    "\n",
    "    img = img.astype('float32')\n",
    "\n",
    "    new_h = WIDTH\n",
    "    if h < new_h:\n",
    "        add_zeros = np.full((w, new_h - h, 3), 255)\n",
    "        img = np.concatenate((img, add_zeros), axis=1)\n",
    "\n",
    "    if h > new_h:\n",
    "        img = cv2.resize(img, (new_h, new_w))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# GENERATE IMAGES FROM FOLDER\n",
    "def generate_data(img_paths):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    names : list of str\n",
    "        paths to images\n",
    "    returns\n",
    "    ---\n",
    "    data_images : list of np.array\n",
    "        images in np.array format\n",
    "    \"\"\"\n",
    "    data_images = []\n",
    "    for path in tqdm(img_paths):\n",
    "        img = np.asarray(Image.open(path).convert('RGB'))\n",
    "        try:\n",
    "            img = process_image(img)\n",
    "            data_images.append(img.astype('uint8'))\n",
    "        except:\n",
    "            print(path)\n",
    "            img = process_image(img)\n",
    "    return data_images\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, loader, case=True, punct=True):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    model : nn.Module\n",
    "    criterion : nn.Object\n",
    "    loader : torch.utils.data.DataLoader\n",
    "\n",
    "    returns\n",
    "    ---\n",
    "    epoch_loss / len(loader) : float\n",
    "        overall loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    metrics = {'loss': 0, 'wer': 0, 'cer': 0}\n",
    "    result = {'true': [], 'predicted': [], 'wer': []}\n",
    "    with torch.no_grad():\n",
    "        for (src, trg) in tqdm(loader):\n",
    "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "            logits = model(src, trg[:-1, :])\n",
    "            loss = criterion(logits.view(-1, logits.shape[-1]), torch.reshape(trg[1:, :], (-1,)))\n",
    "            out_indexes = model.predict(src)\n",
    "            \n",
    "            true_phrases = [indicies_to_text(trg.T[i][1:], ALPHABET) for i in range(BATCH_SIZE)]\n",
    "            pred_phrases = [indicies_to_text(out_indexes[i], ALPHABET) for i in range(BATCH_SIZE)]\n",
    "            \n",
    "            if not case:\n",
    "                true_phrases = [phrase.lower() for phrase in true_phrases]\n",
    "                pred_phrases = [phrase.lower() for phrase in pred_phrases]\n",
    "            if not punct:\n",
    "                true_phrases = [phrase.translate(str.maketrans('', '', string.punctuation))\\\n",
    "                                for phrase in true_phrases]\n",
    "                pred_phrases = [phrase.translate(str.maketrans('', '', string.punctuation))\\\n",
    "                                for phrase in pred_phrases]\n",
    "            \n",
    "            metrics['loss'] += loss.item()\n",
    "            metrics['cer'] += sum([char_error_rate(true_phrases[i], pred_phrases[i]) \\\n",
    "                        for i in range(BATCH_SIZE)])/BATCH_SIZE\n",
    "            metrics['wer'] += sum([int(true_phrases[i] != pred_phrases[i]) \\\n",
    "                        for i in range(BATCH_SIZE)])/BATCH_SIZE\n",
    "\n",
    "            for i in range(len(true_phrases)):\n",
    "              result['true'].append(true_phrases[i])\n",
    "              result['predicted'].append(pred_phrases[i])\n",
    "              result['wer'].append(char_error_rate(true_phrases[i], pred_phrases[i]))\n",
    "\n",
    "    for key in metrics.keys():\n",
    "      metrics[key] /= len(loader)\n",
    "\n",
    "    return metrics, result\n",
    "\n",
    "\n",
    "# MAKE PREDICTION\n",
    "def prediction(model, test_dir, char2idx, idx2char):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    model : nn.Module\n",
    "    test_dir : str\n",
    "        path to directory with images\n",
    "    char2idx : dict\n",
    "        map from chars to indicies\n",
    "    id2char : dict\n",
    "        map from indicies to chars\n",
    "\n",
    "    returns\n",
    "    ---\n",
    "    preds : dict\n",
    "        key : name of image in directory\n",
    "        value : dict with keys ['p_value', 'predicted_label']\n",
    "    \"\"\"\n",
    "    preds = {}\n",
    "    os.makedirs('/output', exist_ok=True)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for filename in os.listdir(test_dir):\n",
    "            img = Image.open(test_dir + filename).convert('RGB')\n",
    "\n",
    "            img = process_image(np.asarray(img)).astype('uint8')\n",
    "            img = img / img.max()\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "            src = torch.FloatTensor(img).unsqueeze(0).to(DEVICE)\n",
    "            if CHANNELS == 1:\n",
    "              src = transforms.Grayscale(CHANNELS)(src)\n",
    "            out_indexes = model.predict(src)\n",
    "            pred = indicies_to_text(out_indexes[0], idx2char)\n",
    "            preds[filename] = pred\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __init__(self, X_type=None, Y_type=None):\n",
    "        self.X_type = X_type\n",
    "\n",
    "    def __call__(self, X):\n",
    "        X = X.transpose((2, 0, 1))\n",
    "        X = torch.from_numpy(X)\n",
    "        if self.X_type is not None:\n",
    "            X = X.type(self.X_type)\n",
    "        return X\n",
    "\n",
    "\n",
    "def log_config(model):\n",
    "    print('transformer layers: {}'.format(model.enc_layers))\n",
    "    print('transformer heads: {}'.format(model.transformer.nhead))\n",
    "    print('hidden dim: {}'.format(model.decoder.embedding_dim))\n",
    "    print('num classes: {}'.format(model.decoder.num_embeddings))\n",
    "    print('backbone: {}'.format(model.backbone_name))\n",
    "    print('dropout: {}'.format(model.pos_encoder.dropout.p))\n",
    "    print(f'{count_parameters(model):,} trainable parameters')\n",
    "\n",
    "\n",
    "def log_metrics(metrics, path_to_logs=None):\n",
    "    if path_to_logs != None:\n",
    "      f = open(path_to_logs, 'a')\n",
    "    if metrics['epoch'] == 1:\n",
    "      if path_to_logs != None:\n",
    "        f.write('Epoch\\tTrain_loss\\tValid_loss\\tCER\\tWER\\tTime\\n')\n",
    "      print('Epoch   Train_loss   Valid_loss   CER   WER    Time    LR')\n",
    "      print('-----   -----------  ----------   ---   ---    ----    ---')\n",
    "    print('{:02d}       {:.6f}         {:.6f}       {:.2f}   {:.2f}   {:.2f}   {:.7f}'.format(\\\n",
    "        metrics['epoch'], metrics['train_loss'], metrics['loss'], metrics['cer'], \\\n",
    "        metrics['wer'], metrics['time'], metrics['lr']))\n",
    "    if path_to_logs != None:\n",
    "      f.write(str(metrics['epoch'])+'\\t'+str(metrics['train_loss'])+'\\t'+str(metrics['loss'])+'\\t'+str(metrics['cer'])+'\\t'+str(metrics['wer'])+'\\t'+str(metrics['time'])+'\\n')\n",
    "      f.close()\n",
    "        \n",
    "\n",
    "# plot images\n",
    "def show_img_grid(images, labels, N):\n",
    "    n = int(N**(0.5))\n",
    "    k = 0\n",
    "    f, axarr = plt.subplots(n,n,figsize=(10,10))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            axarr[i,j].set_title(labels[k])\n",
    "            axarr[i,j].imshow(images[k])\n",
    "            k += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c94c0ce",
   "metadata": {
    "papermill": {
     "duration": 0.011049,
     "end_time": "2023-06-16T02:12:04.932069",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.921020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12eb51b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:04.952070Z",
     "iopub.status.busy": "2023-06-16T02:12:04.951676Z",
     "iopub.status.idle": "2023-06-16T02:12:04.977568Z",
     "shell.execute_reply": "2023-06-16T02:12:04.976758Z"
    },
    "papermill": {
     "duration": 0.038893,
     "end_time": "2023-06-16T02:12:04.980039",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.941146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:1436: UserWarning: The parameter 'fillcolor' is deprecated since 0.12 and will be removed in 0.14. Please use 'fill' instead.\n",
      "  \"The parameter 'fillcolor' is deprecated since 0.12 and will be removed in 0.14. \"\n"
     ]
    }
   ],
   "source": [
    "# text to array of indicies\n",
    "def text_to_labels(s, char2idx):\n",
    "    return [char2idx['SOS']] + [char2idx[i] for i in s if i in char2idx.keys()] + [char2idx['EOS']]\n",
    "\n",
    "# store list of images' names (in directory) and does some operations with images\n",
    "class TextLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_name, labels, transforms, char2idx, idx2char):\n",
    "        \"\"\"\n",
    "        params\n",
    "        ---\n",
    "        images_name : list\n",
    "            list of names of images (paths to images)\n",
    "        labels : list\n",
    "            list of labels to correspondent images from images_name list\n",
    "        char2idx : dict\n",
    "        idx2char : dict\n",
    "        \"\"\"\n",
    "        self.images_name = images_name\n",
    "        self.labels = labels\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.transform = transforms\n",
    "\n",
    "    def _transform(self, X):\n",
    "        j = np.random.randint(0, 3, 1)[0]\n",
    "        if j == 0:\n",
    "            return self.transform(X)\n",
    "        if j == 1:\n",
    "            return tt(ld(vignet(X)))\n",
    "        if j == 2:\n",
    "            return tt(ld(un(X)))\n",
    "            \n",
    "\n",
    "    # shows some stats about dataset\n",
    "    def get_info(self):\n",
    "        N = len(self.labels)\n",
    "        max_len = -1\n",
    "        for label in self.labels:\n",
    "            if len(label) > max_len:\n",
    "                max_len = len(label)\n",
    "        counter = Counter(''.join(self.labels))\n",
    "        counter = dict(sorted(counter.items(), key=lambda item: item[1]))\n",
    "        print(\n",
    "            'Size of dataset: {}\\nMax length of expression: {}\\nThe most common char: {}\\nThe least common char: {}'.format( \\\n",
    "                N, max_len, list(counter.items())[-1], list(counter.items())[0]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images_name[index]\n",
    "        img = self.transform(img)\n",
    "        img = img / img.max()\n",
    "        img = img ** (random.random() * 0.7 + 0.6)\n",
    "\n",
    "        label = text_to_labels(self.labels[index], self.char2idx)\n",
    "        return (torch.FloatTensor(img), torch.LongTensor(label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "# MAKE TEXT TO BE THE SAME LENGTH\n",
    "class TextCollate():\n",
    "    def __call__(self, batch):\n",
    "        x_padded = []\n",
    "        y_padded = torch.LongTensor(LENGTH, len(batch))\n",
    "        y_padded.zero_()\n",
    "\n",
    "        for i in range(len(batch)):\n",
    "            x_padded.append(batch[i][0].unsqueeze(0))\n",
    "            y = batch[i][1]\n",
    "            y_padded[:y.size(0), i] = y\n",
    "\n",
    "        x_padded = torch.cat(x_padded)\n",
    "        return x_padded, y_padded\n",
    "    \n",
    "\n",
    "p = Augmentor.Pipeline()\n",
    "p.shear(max_shear_left=2, max_shear_right=2, probability=0.7)\n",
    "p.random_distortion(probability=1.0, grid_width=3, grid_height=3, magnitude=11)\n",
    "\n",
    "TRAIN_TRANSFORMS = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Grayscale(CHANNELS),\n",
    "            p.torch_transform(),  # random distortion and shear\n",
    "            transforms.ColorJitter(contrast=(0.5,1),saturation=(0.5,1)),\n",
    "            transforms.RandomRotation(degrees=(-9, 9)),\n",
    "            transforms.RandomAffine(10, None, [0.6 ,1] ,3 ,fillcolor=255),\n",
    "            #transforms.transforms.GaussianBlur(3, sigma=(0.1, 1.9)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "TEST_TRANSFORMS = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Grayscale(CHANNELS),\n",
    "            transforms.ToTensor()\n",
    "        ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c64f10a",
   "metadata": {
    "papermill": {
     "duration": 0.009153,
     "end_time": "2023-06-16T02:12:04.998521",
     "exception": false,
     "start_time": "2023-06-16T02:12:04.989368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f45c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:05.024187Z",
     "iopub.status.busy": "2023-06-16T02:12:05.023780Z",
     "iopub.status.idle": "2023-06-16T02:12:05.064104Z",
     "shell.execute_reply": "2023-06-16T02:12:05.063180Z"
    },
    "papermill": {
     "duration": 0.057382,
     "end_time": "2023-06-16T02:12:05.066884",
     "exception": false,
     "start_time": "2023-06-16T02:12:05.009502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, outtoken, hidden, enc_layers=1, dec_layers=1, nhead=1, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.backbone_name = 'conv(64)->conv(64)->conv(128)->conv(256)->conv(256)->conv(512)->conv(512)'\n",
    "\n",
    "        self.conv0 = Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv1 = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv2 = Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1))\n",
    "        self.conv3 = Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv4 = Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1))\n",
    "        self.conv5 = Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv6 = Conv2d(512, 512, kernel_size=(2, 1), stride=(1, 1))\n",
    "        \n",
    "        self.pool1 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.pool3 = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.pool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.bn0 = BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn1 = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn2 = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn3 = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn4 = BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn5 = BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.bn6 = BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.activ = LeakyReLU()\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(hidden, dropout)\n",
    "        self.decoder = nn.Embedding(outtoken, hidden)\n",
    "        self.pos_decoder = PositionalEncoding(hidden, dropout)\n",
    "        self.transformer = nn.Transformer(d_model=hidden, nhead=nhead, num_encoder_layers=enc_layers,\n",
    "                                          num_decoder_layers=dec_layers, dim_feedforward=hidden * 4, dropout=dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden, outtoken)\n",
    "        self.src_mask = None\n",
    "        self.trg_mask = None\n",
    "        self.memory_mask = None\n",
    "        \n",
    "        log_config(self)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz, device=DEVICE), 1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def make_len_mask(self, inp):\n",
    "        return (inp == 0).transpose(0, 1)\n",
    "    \n",
    "    def _get_features(self, src):\n",
    "        '''\n",
    "        params\n",
    "        ---\n",
    "        src : Tensor [64, 3, 64, 256] : [B,C,H,W]\n",
    "            B - batch, C - channel, H - height, W - width\n",
    "        returns\n",
    "        ---\n",
    "        x : Tensor : [W,B,C*H]\n",
    "        '''\n",
    "        x = self.activ(self.bn0(self.conv0(src)))\n",
    "        x = self.activ(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(self.activ(self.bn1(self.conv1(x))))\n",
    "        x = self.activ(self.bn2(self.conv2(x)))\n",
    "        x = self.activ(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(self.activ(self.bn3(self.conv3(x))))\n",
    "        x = self.activ(self.bn4(self.conv4(x)))\n",
    "        x = self.activ(self.bn5(self.conv5(x)))\n",
    "        x = self.pool5(self.activ(self.bn5(self.conv5(x))))\n",
    "        x = self.activ(self.bn6(self.conv6(x)))\n",
    "        x = x.permute(0, 3, 1, 2).flatten(2).permute(1, 0, 2)\n",
    "        return x\n",
    "\n",
    "    def predict(self, batch):\n",
    "        '''\n",
    "        params\n",
    "        ---\n",
    "        batch : Tensor [64, 3, 64, 256] : [B,C,H,W]\n",
    "            B - batch, C - channel, H - height, W - width\n",
    "        \n",
    "        returns\n",
    "        ---\n",
    "        result : List [64, -1] : [B, -1]\n",
    "            preticted sequences of tokens' indexes\n",
    "        '''\n",
    "        result = []\n",
    "        for item in batch:\n",
    "          x = self._get_features(item.unsqueeze(0))\n",
    "          memory = self.transformer.encoder(self.pos_encoder(x))\n",
    "          out_indexes = [ALPHABET.index('SOS'), ]\n",
    "          for i in range(100):\n",
    "              trg_tensor = torch.LongTensor(out_indexes).unsqueeze(1).to(DEVICE)\n",
    "              output = self.fc_out(self.transformer.decoder(self.pos_decoder(self.decoder(trg_tensor)), memory))\n",
    "\n",
    "              out_token = output.argmax(2)[-1].item()\n",
    "              out_indexes.append(out_token)\n",
    "              if out_token == ALPHABET.index('EOS'):\n",
    "                  break\n",
    "          result.append(out_indexes)\n",
    "        return result\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        '''\n",
    "        params\n",
    "        ---\n",
    "        src : Tensor [64, 3, 64, 256] : [B,C,H,W]\n",
    "            B - batch, C - channel, H - height, W - width\n",
    "        trg : Tensor [13, 64] : [L,B]\n",
    "            L - max length of label\n",
    "        '''\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_subsequent_mask(len(trg)).to(trg.device) \n",
    "\n",
    "        x = self._get_features(src)\n",
    "        src_pad_mask = self.make_len_mask(x[:, :, 0])\n",
    "        src = self.pos_encoder(x)\n",
    "        trg_pad_mask = self.make_len_mask(trg)\n",
    "        trg = self.decoder(trg)\n",
    "        trg = self.pos_decoder(trg)\n",
    "\n",
    "        output = self.transformer(src, trg, src_mask=self.src_mask, tgt_mask=self.trg_mask,\n",
    "                                  memory_mask=self.memory_mask,\n",
    "                                  src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=trg_pad_mask,\n",
    "                                  memory_key_padding_mask=src_pad_mask)\n",
    "        output = self.fc_out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0718f40",
   "metadata": {
    "papermill": {
     "duration": 0.009136,
     "end_time": "2023-06-16T02:12:05.086438",
     "exception": false,
     "start_time": "2023-06-16T02:12:05.077302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f02db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:05.106234Z",
     "iopub.status.busy": "2023-06-16T02:12:05.105845Z",
     "iopub.status.idle": "2023-06-16T02:12:05.119090Z",
     "shell.execute_reply": "2023-06-16T02:12:05.118053Z"
    },
    "papermill": {
     "duration": 0.026198,
     "end_time": "2023-06-16T02:12:05.121906",
     "exception": false,
     "start_time": "2023-06-16T02:12:05.095708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    model : nn.Module\n",
    "    optimizer : nn.Object\n",
    "    criterion : nn.Object\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "    returns\n",
    "    ---\n",
    "    epoch_loss / len(train_loader) : float\n",
    "        overall loss\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in tqdm(train_loader):\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:-1, :])\n",
    "\n",
    "        loss = criterion(output.view(-1, output.shape[-1]), torch.reshape(trg[1:, :], (-1,)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(train_loader)\n",
    "\n",
    "\n",
    "# GENERAL FUNCTION FROM TRAINING AND VALIDATION\n",
    "def fit(model, optimizer, scheduler, criterion, train_loader, val_loader, start_epoch=0, end_epoch=10):\n",
    "    metrics = []\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        epoch_metrics = {}\n",
    "        start_time = time()\n",
    "        train_loss = train(model, optimizer, criterion, train_loader)\n",
    "        end_time = time()\n",
    "        epoch_metrics, _ = evaluate(model, criterion, val_loader)\n",
    "        epoch_metrics['train_loss'] = train_loss\n",
    "        epoch_metrics['epoch'] = epoch\n",
    "        epoch_metrics['time'] = end_time - start_time\n",
    "        epoch_metrics['lr'] = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"loss\": train_loss})\n",
    "        metrics.append(epoch_metrics)\n",
    "        log_metrics(epoch_metrics, TRAIN_LOG)\n",
    "        if scheduler != None:\n",
    "            scheduler.step(epoch_metrics['loss'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e8dc016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:12:05.144347Z",
     "iopub.status.busy": "2023-06-16T02:12:05.143992Z",
     "iopub.status.idle": "2023-06-16T02:24:54.205661Z",
     "shell.execute_reply": "2023-06-16T02:24:54.204343Z"
    },
    "papermill": {
     "duration": 769.074238,
     "end_time": "2023-06-16T02:24:54.207722",
     "exception": false,
     "start_time": "2023-06-16T02:12:05.133484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset /kaggle/input/data-gray/images/ ...\n",
      "ValueError: ['']\n",
      "ValueError: ['']\n",
      "ValueError: ['']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87101/87101 [12:05<00:00, 120.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset /kaggle/input/data-gray/images/ ...\n",
      "ValueError: ['']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:42<00:00, 117.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATASET:\n",
      "Size of dataset: 87101\n",
      "Max length of expression: 10\n",
      "The most common char: ('/', 174102)\n",
      "The least common char: ('.', 20)\n",
      "\n",
      "TEST DATASET:\n",
      "Size of dataset: 5000\n",
      "Max length of expression: 10\n",
      "The most common char: ('/', 10000)\n",
      "The least common char: ('3', 3913)\n"
     ]
    }
   ],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "char2idx = {char: idx for idx, char in enumerate(ALPHABET)}\n",
    "idx2char = {idx: char for idx, char in enumerate(ALPHABET)}\n",
    "\n",
    "print(f\"loading dataset {PATH_TRAIN_DIR} ...\")\n",
    "img2label, _, all_words = process_data(PATH_TRAIN_DIR, PATH_TRAIN_LABELS) \n",
    "img_names, labels = list(img2label.keys()), list(img2label.values())\n",
    "\n",
    "img2label1, _, all_words = process_data('/kaggle/input/more-data/new/', '/kaggle/input/more-data/trainnew.csv') \n",
    "img_names1, labels1 = list(img2label1.keys()), list(img2label1.values())\n",
    "\n",
    "img2label2, _, all_words = process_data('/kaggle/input/test-data/test/', '/kaggle/input/test-data/process.csv') \n",
    "img_names2, labels2 = list(img2label2.keys()), list(img2label2.values())\n",
    "\n",
    "\n",
    "img_names = img_names[30000:100000] \n",
    "labels    = labels[30000:100000] \n",
    "img_names += img_names1[10000: 30000]\n",
    "labels    += labels1[10000: 30000]\n",
    "\n",
    "\n",
    "for i in range(20) : \n",
    "    img_names += img_names2[1:]\n",
    "    labels    += labels2[1:]\n",
    "    \n",
    "X_train = generate_data(img_names)\n",
    "y_train = labels\n",
    "\n",
    "train_dataset = TextLoader(X_train, y_train, TRAIN_TRANSFORMS, char2idx, idx2char)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True,\n",
    "                                           batch_size=BATCH_SIZE, pin_memory=True,\n",
    "                                           drop_last=True, collate_fn=TextCollate())\n",
    "\n",
    "print(f\"loading dataset {PATH_TEST_DIR} ...\")\n",
    "img2label, _, all_words = process_data(PATH_TEST_DIR, PATH_TEST_LABELS) \n",
    "img_names, labels = list(img2label.keys()), list(img2label.values())\n",
    "\n",
    "img_names = img_names[1:] \n",
    "labels    = labels[1:]\n",
    "\n",
    "X_test = generate_data(img_names)\n",
    "y_test = labels\n",
    "\n",
    "test_dataset = TextLoader(X_test, y_test, TEST_TRANSFORMS, char2idx ,idx2char)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True,\n",
    "                                           batch_size=BATCH_SIZE, pin_memory=True,\n",
    "                                           drop_last=True, collate_fn=TextCollate())\n",
    "\n",
    "print(\"TRAIN DATASET:\")\n",
    "train_dataset.get_info()\n",
    "print(\"\\nTEST DATASET:\")\n",
    "test_dataset.get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ccdf47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T02:24:55.333843Z",
     "iopub.status.busy": "2023-06-16T02:24:55.333121Z",
     "iopub.status.idle": "2023-06-16T02:25:05.565873Z",
     "shell.execute_reply": "2023-06-16T02:25:05.564477Z"
    },
    "papermill": {
     "duration": 10.772177,
     "end_time": "2023-06-16T02:25:05.568417",
     "exception": true,
     "start_time": "2023-06-16T02:24:54.796240",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer layers: 2\n",
      "transformer heads: 4\n",
      "hidden dim: 512\n",
      "num classes: 14\n",
      "backbone: conv(64)->conv(64)->conv(128)->conv(256)->conv(256)->conv(512)->conv(512)\n",
      "dropout: 0.2\n",
      "19,758,224 trainable parameters\n",
      "checkpoints are saved in ./ every 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1360 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 64, 3, 3], expected input[64, 128, 64, 256] to have 64 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/1966723669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'checkpoints are saved in {CHECKPOINT_PATH} every {CHECKPOINT_FREQ} epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_FREQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mCHECKPOINT_FREQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'checkpoint_{}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mCHECKPOINT_FREQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23/2001593910.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, optimizer, scheduler, criterion, train_loader, val_loader, start_epoch, end_epoch)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mepoch_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mepoch_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23/2001593910.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23/1382996877.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0msrc_pad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_len_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23/1382996877.py\u001b[0m in \u001b[0;36m_get_features\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 64, 3, 3], expected input[64, 128, 64, 256] to have 64 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(len(ALPHABET), hidden=HIDDEN, enc_layers=ENC_LAYERS, dec_layers=DEC_LAYERS,   \n",
    "                          nhead=N_HEADS, dropout=DROPOUT).to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load('/kaggle/input/trainmodel/model.pt'))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=char2idx['PAD'])\n",
    "optimizer = torch.optim.__getattribute__(OPTIMIZER_NAME)(model.parameters(), lr=LR)\n",
    "\n",
    "if SCHUDULER_ON:\n",
    "    scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=PATIENCE)\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "print(f'checkpoints are saved in {CHECKPOINT_PATH} every {CHECKPOINT_FREQ} epochs')\n",
    "for epoch in range(1, N_EPOCHS, CHECKPOINT_FREQ):\n",
    "    fit(model, optimizer, scheduler, criterion, train_loader, test_loader, epoch, epoch+CHECKPOINT_FREQ)\n",
    "    torch.save(model.state_dict(), CHECKPOINT_PATH+'checkpoint_{}.pt'.format(epoch+CHECKPOINT_FREQ))\n",
    "    \n",
    "    artifact = wandb.Artifact(name='new', type='model')\n",
    "    artifact.add_file('/kaggle/working/' + 'checkpoint_{}.pt'.format(epoch+CHECKPOINT_FREQ))\n",
    "    run.log_artifact(artifact)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c990b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T21:20:21.158768Z",
     "iopub.status.busy": "2023-06-15T21:20:21.158329Z",
     "iopub.status.idle": "2023-06-15T21:20:21.424234Z",
     "shell.execute_reply": "2023-06-15T21:20:21.423350Z",
     "shell.execute_reply.started": "2023-06-15T21:20:21.158726Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdabf82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T21:20:21.426097Z",
     "iopub.status.busy": "2023-06-15T21:20:21.425722Z",
     "iopub.status.idle": "2023-06-15T21:20:21.774271Z",
     "shell.execute_reply": "2023-06-15T21:20:21.773158Z",
     "shell.execute_reply.started": "2023-06-15T21:20:21.426061Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "artifact = wandb.Artifact(name='new', type='model')\n",
    "artifact.add_file('/kaggle/working/model.pt')\n",
    "run.log_artifact(artifact)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac1c1fb1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a4547",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-15T21:20:21.775558Z",
     "iopub.status.idle": "2023-06-15T21:20:21.776202Z",
     "shell.execute_reply": "2023-06-15T21:20:21.775977Z",
     "shell.execute_reply.started": "2023-06-15T21:20:21.775952Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load weights\n",
    "# model = TransformerModel(len(ALPHABET), hidden=HIDDEN, enc_layers=ENC_LAYERS, dec_layers=DEC_LAYERS,   \n",
    "#                           nhead=N_HEADS, dropout=DROPOUT).to(DEVICE)\n",
    "# model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "\n",
    "# evaluate\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=char2idx['PAD'])\n",
    "metrics, result = evaluate(model, criterion, test_loader, case=CASE, punct=PUNCT)\n",
    "\n",
    "if PATH_TEST_RESULTS != None:\n",
    "  f = open(PATH_TEST_RESULTS, 'w')\n",
    "  f.write(\"true\\tpredicted\\twer\\n\")\n",
    "  for i in range(len(result['true'])): \n",
    "    f.write(result['true'][i]+\\\n",
    "            '\\t'+result['predicted'][i]+\\\n",
    "            '\\t'+str(result['wer'][i])+'\\n')\n",
    "print(f'PUNCT: {PUNCT}, CASE: {CASE}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956feb8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-15T21:20:21.777474Z",
     "iopub.status.idle": "2023-06-15T21:20:21.778115Z",
     "shell.execute_reply": "2023-06-15T21:20:21.777896Z",
     "shell.execute_reply.started": "2023-06-15T21:20:21.777868Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read predictions and show it\n",
    "df = pd.read_csv(PATH_TEST_RESULTS, sep='\\t', quoting=3)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f300b78",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-15T21:20:21.779295Z",
     "iopub.status.idle": "2023-06-15T21:20:21.779965Z",
     "shell.execute_reply": "2023-06-15T21:20:21.779738Z",
     "shell.execute_reply.started": "2023-06-15T21:20:21.779712Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = prediction(model, PREDICT_PATH, char2idx, idx2char)\n",
    "\n",
    "f = open(DIR+'/predictions.tsv', 'w')\n",
    "f.write('filename\\tprediction\\n')\n",
    "for item in preds.items():\n",
    "    f.write(item[0]+'\\t'+item[1]+'\\n')\n",
    "f.close()\n",
    "print(f'predictions are saved in {DIR}predictions.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b097e1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-15T21:20:21.781144Z",
     "iopub.status.idle": "2023-06-15T21:20:21.781806Z",
     "shell.execute_reply": "2023-06-15T21:20:21.781585Z",
     "shell.execute_reply.started": "2023-06-15T21:20:21.781560Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DIR+'/predictions.tsv', sep='\\t', quoting=3)\n",
    "N = 9\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(N):\n",
    "    idx = random.randint(0, len(df))\n",
    "    image_path = PATH_TEST_DIR + df.iloc[idx]['filename']\n",
    "    predicted_label = df.iloc[idx]['prediction']\n",
    "\n",
    "    images.append(Image.open(image_path))\n",
    "    labels.append(predicted_label)\n",
    "\n",
    "show_img_grid(images, labels, N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 830.737383,
   "end_time": "2023-06-16T02:25:09.168538",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-16T02:11:18.431155",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03b012a4af6e44d2835e6f1d5b7ca835": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "07ececccd93b43b18d4dbfb6d05d1bdd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20ecb5e47ce143b788c9c36f29285ca5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22af0175be0247be9e361fc0d3956532": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07ececccd93b43b18d4dbfb6d05d1bdd",
       "placeholder": "​",
       "style": "IPY_MODEL_2e920c436d0d41aeb12322ffea7341d9",
       "value": ""
      }
     },
     "2e920c436d0d41aeb12322ffea7341d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "31f84ee8627f4496b7911d2c1e801856": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3ad932b9394841fbbb496fa1512b0399",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_70b593a18bbc4dcfaf4d88e42980f8ec",
       "value": 0
      }
     },
     "3ad932b9394841fbbb496fa1512b0399": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d415322603141128f2f5e8b85920375": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "699bae03386549a9a7f34ebeb20131ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20ecb5e47ce143b788c9c36f29285ca5",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ac7f75b329f8425d8cdaeba8335a6354",
       "value": 0
      }
     },
     "70b593a18bbc4dcfaf4d88e42980f8ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "785c0039552e484292b7c4be236d566a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f585bb9e867f47ec893b582da877af2c",
        "IPY_MODEL_699bae03386549a9a7f34ebeb20131ae"
       ],
       "layout": "IPY_MODEL_4d415322603141128f2f5e8b85920375"
      }
     },
     "ac7f75b329f8425d8cdaeba8335a6354": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d67f632127294c0abf1569439695d251": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_22af0175be0247be9e361fc0d3956532",
        "IPY_MODEL_31f84ee8627f4496b7911d2c1e801856"
       ],
       "layout": "IPY_MODEL_03b012a4af6e44d2835e6f1d5b7ca835"
      }
     },
     "e6df2c8e87494fc9858bc195822d6d2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f585bb9e867f47ec893b582da877af2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f80c3b767b6947ac948ddf036e4a9d23",
       "placeholder": "​",
       "style": "IPY_MODEL_e6df2c8e87494fc9858bc195822d6d2b",
       "value": ""
      }
     },
     "f80c3b767b6947ac948ddf036e4a9d23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
